{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775258b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 20:28:39,178 [INFO] ====== 조형태 교수님 (https://scholar.google.com/citations?hl=ko&user=QsjS7I4AAAAJ) 크롤링 시작 ======\n",
      "조형태 교수님 논문 추출 중: 100%|██████████| 154/154 [00:12<00:00, 12.72it/s]\n",
      "2025-09-17 20:28:58,861 [INFO] ====== 이재원 교수님 (https://scholar.google.co.kr/citations?user=guPkb4cAAAAJ&hl=ko) 크롤링 시작 ======\n",
      "이재원 교수님 논문 추출 중: 100%|██████████| 56/56 [00:03<00:00, 15.30it/s]\n",
      "2025-09-17 20:29:08,485 [INFO] ====== 가성빈 교수님 (https://scholar.google.com/citations?hl=ko&user=YZ5rW_gAAAAJ) 크롤링 시작 ======\n",
      "가성빈 교수님 논문 추출 중: 100%|██████████| 48/48 [00:03<00:00, 15.64it/s]\n",
      "2025-09-17 20:29:15,800 [INFO] ====== 최동호 (https://scholar.google.com/citations?hl=ko&user=JHi2ay4AAAAJ) 크롤링 시작 ======\n",
      "최동호 논문 추출 중: 100%|██████████| 40/40 [00:02<00:00, 13.77it/s]\n",
      "2025-09-17 20:29:23,649 [INFO] ====== 안나현 (https://scholar.google.com/citations?hl=ko&user=5gsoA1EAAAAJ) 크롤링 시작 ======\n",
      "안나현 논문 추출 중: 100%|██████████| 18/18 [00:01<00:00, 14.60it/s]\n",
      "2025-09-17 20:29:27,433 [INFO] ====== 주종효 (https://scholar.google.co.kr/citations?user=GdFcc0QAAAAJ&hl=ko&oi=sra) 크롤링 시작 ======\n",
      "주종효 논문 추출 중: 100%|██████████| 49/49 [00:03<00:00, 15.27it/s]\n",
      "2025-09-17 20:29:34,871 [INFO] ====== 김유림 (https://scholar.google.co.kr/citations?user=66OKDcgAAAAJ&hl=ko&oi=sra) 크롤링 시작 ======\n",
      "김유림 논문 추출 중: 100%|██████████| 26/26 [00:01<00:00, 15.36it/s]\n",
      "2025-09-17 20:29:41,525 [INFO] ====== 윤승관 (https://scholar.google.co.kr/citations?user=HDVnd5YAAAAJ&hl=ko&oi=sra) 크롤링 시작 ======\n",
      "윤승관 논문 추출 중: 100%|██████████| 8/8 [00:00<00:00, 14.92it/s]\n",
      "2025-09-17 20:29:44,606 [INFO] 크롤링 완료\n",
      "2025-09-17 20:29:44,611 [INFO] 총 399개 논문을 scholar_papers_all.csv에 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "\n",
    "# ---------------- 로깅 설정 ----------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# ---------------- 대상 인물 리스트 ----------------\n",
    "professors = {\n",
    "    \"조형태 교수님\": \"https://scholar.google.com/citations?hl=ko&user=QsjS7I4AAAAJ\",\n",
    "    \"이재원 교수님\": \"https://scholar.google.co.kr/citations?user=guPkb4cAAAAJ&hl=ko\",\n",
    "    \"가성빈 교수님\": \"https://scholar.google.com/citations?hl=ko&user=YZ5rW_gAAAAJ\",\n",
    "    \"최동호\": \"https://scholar.google.com/citations?hl=ko&user=JHi2ay4AAAAJ\",\n",
    "    \"안나현\": \"https://scholar.google.com/citations?hl=ko&user=5gsoA1EAAAAJ\",\n",
    "    \"주종효\": \"https://scholar.google.co.kr/citations?user=GdFcc0QAAAAJ&hl=ko&oi=sra\",\n",
    "    \"김유림\": \"https://scholar.google.co.kr/citations?user=66OKDcgAAAAJ&hl=ko&oi=sra\",\n",
    "    \"윤승관\": \"https://scholar.google.co.kr/citations?user=HDVnd5YAAAAJ&hl=ko&oi=sra\",\n",
    "    # 권혁원, 강현진, 이세영 등 URL 없는 분들은 제외\n",
    "}\n",
    "\n",
    "# ---------------- 브라우저 실행 ----------------\n",
    "options = Options()\n",
    "# options.add_argument(\"--headless\")  # 브라우저 창 안 띄움\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "service = Service(\"c:/Users/PSID_PC_20/Desktop/[00]Projects/PSID_ARCHIVE/chromedriver-win64/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "all_papers = []\n",
    "\n",
    "# ---------------- 개별 Scholar 페이지 순회 ----------------\n",
    "for name, url in professors.items():\n",
    "    logging.info(f\"====== {name} ({url}) 크롤링 시작 ======\")\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # \"더보기\" 버튼 계속 클릭\n",
    "    while True:\n",
    "        try:\n",
    "            more_button = driver.find_element(By.ID, \"gsc_bpf_more\")\n",
    "            if more_button.is_enabled():\n",
    "                driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                time.sleep(1.5)\n",
    "            else:\n",
    "                break\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            break\n",
    "\n",
    "    # 논문 데이터 추출\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, \"#gsc_a_t tr.gsc_a_tr\")\n",
    "\n",
    "    for row in tqdm(rows, desc=f\"{name} 논문 추출 중\"):\n",
    "        try:\n",
    "            title_elem = row.find_element(By.CSS_SELECTOR, \"a.gsc_a_at\")\n",
    "            title = title_elem.text\n",
    "            link = title_elem.get_attribute(\"href\")\n",
    "        except:\n",
    "            title, link = \"\", \"\"\n",
    "\n",
    "        try:\n",
    "            authors = row.find_element(By.CSS_SELECTOR, \".gsc_a_at+div\").text\n",
    "        except:\n",
    "            authors = \"\"\n",
    "\n",
    "        try:\n",
    "            journal = row.find_element(By.CSS_SELECTOR, \".gs_gray+ .gs_gray\").text\n",
    "        except:\n",
    "            journal = \"\"\n",
    "\n",
    "        try:\n",
    "            year = row.find_element(By.CSS_SELECTOR, \".gsc_a_y\").text\n",
    "        except:\n",
    "            year = \"\"\n",
    "\n",
    "        try:\n",
    "            cites_elem = row.find_element(By.CSS_SELECTOR, \".gsc_a_c a\")\n",
    "            cites = cites_elem.text if cites_elem.text else \"0\"\n",
    "        except:\n",
    "            cites = \"0\"\n",
    "\n",
    "        all_papers.append([name, title, authors, journal, year, cites, link])\n",
    "\n",
    "logging.info(\"크롤링 완료\")\n",
    "\n",
    "# ---------------- CSV 저장 ----------------\n",
    "csv_filename = \"scholar_papers_all.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Professor\", \"Title\", \"Authors\", \"Journal/Conference\", \"Year\", \"Citations\", \"Link\"])\n",
    "    writer.writerows(all_papers)\n",
    "\n",
    "logging.info(f\"총 {len(all_papers)}개 논문을 {csv_filename}에 저장 완료\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fab9ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "논문 초록 수집 중: 1it [00:12, 12.48s/it]2025-09-18 13:15:47,382 [WARNING] CrossRef DOI 오류: HTTPSConnectionPool(host='api.crossref.org', port=443): Read timed out. (read timeout=15)\n",
      "논문 초록 수집 중: 2it [00:40, 20.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m title \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# 1) DOI 먼저 확보\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m doi \u001b[38;5;241m=\u001b[39m \u001b[43mget_doi_from_crossref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# 2) DOI 있으면 Semantic Scholar에서 초록 시도\u001b[39;00m\n\u001b[0;32m     53\u001b[0m journal, abstract \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[25], line 19\u001b[0m, in \u001b[0;36mget_doi_from_crossref\u001b[1;34m(title)\u001b[0m\n\u001b[0;32m     17\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery.title\u001b[39m\u001b[38;5;124m\"\u001b[39m: title, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHEADERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     21\u001b[0m         data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\http\\client.py:1386\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1386\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import requests\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "input_csv = \"scholar_papers_all.csv\"\n",
    "output_csv = \"scholar_papers_with_abstract.csv\"\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (compatible; MyResearchBot/1.0)\"}\n",
    "\n",
    "# ---------------- 1단계: CrossRef에서 DOI 가져오기 ----------------\n",
    "def get_doi_from_crossref(title):\n",
    "    url = \"https://api.crossref.org/works\"\n",
    "    params = {\"query.title\": title, \"rows\": 1}\n",
    "    try:\n",
    "        r = requests.get(url, params=params, headers=HEADERS, timeout=15)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            items = data.get(\"message\", {}).get(\"items\", [])\n",
    "            if items:\n",
    "                return items[0].get(\"DOI\", \"\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"CrossRef DOI 오류: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "# ---------------- 2단계: Semantic Scholar DOI로 초록 가져오기 ----------------\n",
    "def get_abstract_from_semanticscholar(doi):\n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/paper/DOI:{doi}\"\n",
    "    params = {\"fields\": \"title,abstract,venue\"}\n",
    "    try:\n",
    "        r = requests.get(url, params=params, headers=HEADERS, timeout=15)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            return data.get(\"venue\", \"\"), data.get(\"abstract\", \"\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Semantic Scholar DOI 오류: {e}\")\n",
    "    return \"\", \"\"\n",
    "\n",
    "# ---------------- 실행 ----------------\n",
    "results = []\n",
    "with open(input_csv, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in tqdm(reader, desc=\"논문 초록 수집 중\"):\n",
    "        title = row[\"Title\"]\n",
    "\n",
    "        # 1) DOI 먼저 확보\n",
    "        doi = get_doi_from_crossref(title)\n",
    "\n",
    "        # 2) DOI 있으면 Semantic Scholar에서 초록 시도\n",
    "        journal, abstract = (\"\", \"\")\n",
    "        if doi:\n",
    "            journal, abstract = get_abstract_from_semanticscholar(doi)\n",
    "\n",
    "        results.append({\n",
    "            \"Title\": title,\n",
    "            \"Journal\": journal if journal else row[\"Journal/Conference\"],\n",
    "            \"Abstract\": abstract\n",
    "        })\n",
    "\n",
    "# ---------------- 저장 ----------------\n",
    "with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"Title\", \"Journal\", \"Abstract\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "logging.info(f\"총 {len(results)}개 논문 초록을 {output_csv}에 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "571573f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 13:20:17,194 [INFO] 원문 링크: https://www.sciencedirect.com/science/article/pii/S0196890421006142\n",
      "2025-09-18 13:20:23,289 [INFO] 추출된 Abstract: Abstract\n",
      "The production and application of hydrogen, an environmentally friendly energy source, have been attracting increasing interest of late. Although steam methane reforming (SMR) method is used to produce hydrogen, it is difficult to build a high-fidelity model because the existing equation-or...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import logging\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "# ---------------- 브라우저 실행 ----------------\n",
    "options = Options()\n",
    "# options.add_argument(\"--headless\")\n",
    "service = Service(\"chromedriver.exe\")   # 경로 수정\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# ---------------- Scholar 접속 ----------------\n",
    "driver.get(\"https://scholar.google.com/citations?hl=ko&user=QsjS7I4AAAAJ\")\n",
    "time.sleep(2)\n",
    "\n",
    "# 첫 번째 논문 클릭\n",
    "first_paper = driver.find_element(By.CSS_SELECTOR, \"tr.gsc_a_tr a.gsc_a_at\")\n",
    "first_paper.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# 오른쪽 패널에서 원문 링크 추출\n",
    "link_elem = driver.find_element(By.CSS_SELECTOR, \"#gsc_oci_title a.gsc_oci_title_link\")\n",
    "paper_url = link_elem.get_attribute(\"href\")\n",
    "logging.info(f\"원문 링크: {paper_url}\")\n",
    "\n",
    "# ---------------- 새 탭 열어서 원문 페이지 접속 ----------------\n",
    "driver.execute_script(\"window.open('');\")\n",
    "driver.switch_to.window(driver.window_handles[1])\n",
    "driver.get(paper_url)\n",
    "time.sleep(5)  # 페이지 로딩 대기 (네트워크 환경에 맞게 조정)\n",
    "\n",
    "abstract_text = \"\"\n",
    "\n",
    "# ---------------- 여러 저널별 Abstract CSS Selector 시도 ----------------\n",
    "try:\n",
    "    # ScienceDirect\n",
    "    elem = driver.find_element(By.CSS_SELECTOR, \"div.abstract.author\")\n",
    "    abstract_text = elem.text\n",
    "except NoSuchElementException:\n",
    "    try:\n",
    "        # Springer\n",
    "        elem = driver.find_element(By.CSS_SELECTOR, \"section.Abstract\")\n",
    "        abstract_text = elem.text\n",
    "    except NoSuchElementException:\n",
    "        try:\n",
    "            # Wiley\n",
    "            elem = driver.find_element(By.CSS_SELECTOR, \"div.article-section__content\")\n",
    "            abstract_text = elem.text\n",
    "        except NoSuchElementException:\n",
    "            logging.warning(\"Abstract 영역을 찾을 수 없음\")\n",
    "\n",
    "logging.info(f\"추출된 Abstract: {abstract_text[:300]}...\")\n",
    "\n",
    "# ---------------- 종료 ----------------\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04725f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:/Users/PSID_PC_20/AppData/Local/Programs/Microsoft VS Code'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.path.abspath(os.path.curdir)\n",
    "strr = 'c:\\\\Users\\\\PSID_PC_20\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code'\n",
    "strr.replace('\\\\','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d50210f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'scholar_papers.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m j \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# ----------- CSV 불러오기 -----------\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscholar_papers.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 파일명 바꿔주세요\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# ----------- 정규화 컬럼 추가 -----------\u001b[39;00m\n\u001b[0;32m     16\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJournalClean\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJournal/Conference\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(normalize_journal)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'scholar_papers.csv'"
     ]
    }
   ],
   "source": [
    "# os.chdir(\"c:/Users/PSID_PC_20/Downloads/\")\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./scholar_papers_all.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c49d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 Unknown 항목 수: 45\n",
      "    Professor                                              Title  \\\n",
      "99    조형태 교수님  Chemical Property-Guided Neural Networks for N...   \n",
      "116   조형태 교수님  Quantum Computing Assisted Data-Driven Modelin...   \n",
      "117   조형태 교수님  Analysis of Correlation between Microbubble an...   \n",
      "118   조형태 교수님  Data-Driven Adaptive Sparse Identification of ...   \n",
      "119   조형태 교수님  Probabilistic Prediction Model-Based High-Thro...   \n",
      "125   조형태 교수님  Improved Long-Short Term Memory Model for Dyna...   \n",
      "126   조형태 교수님  Cost-Optimal Multi-Effect Mechanical Vapor Rec...   \n",
      "127   조형태 교수님  Multi-objective Optimization of Process Effici...   \n",
      "128   조형태 교수님  Guide to COF Adsorbent for Ammonia-based Green...   \n",
      "129   조형태 교수님  Data-Driven Modeling to Predict the Physical P...   \n",
      "130   조형태 교수님  Development of Cement Kiln Dust Recovery Proce...   \n",
      "132   조형태 교수님  A Data-Driven Approach for Modeling and Energy...   \n",
      "134   조형태 교수님  Development of Two Sequential Kmc Models to De...   \n",
      "135   조형태 교수님  Data-Driven Predictive Model and Optimization ...   \n",
      "136   조형태 교수님  Optimization of Fluidized Bed Incineration Pro...   \n",
      "143   조형태 교수님  Development of AI Platform Based on Machine Le...   \n",
      "145   조형태 교수님  Finding the Preferred Safe Operating Condition...   \n",
      "146   조형태 교수님  Noble Method for Evaluating the Distributive M...   \n",
      "148   조형태 교수님  Numerical Analysis of the Effect of Air Inlet ...   \n",
      "150   조형태 교수님  Numerical analysis of gas-solid flow pattern f...   \n",
      "\n",
      "                                    Journal/Conference  \n",
      "99   2023 IEEE 21st International Conference on Ind...  \n",
      "116                          2023 AIChE Annual Meeting  \n",
      "117                          2023 AIChE Annual Meeting  \n",
      "118                          2023 AIChE Annual Meeting  \n",
      "119                          2023 AIChE Annual Meeting  \n",
      "125                          2022 AIChE Annual Meeting  \n",
      "126                          2022 AIChE Annual Meeting  \n",
      "127                          2022 AIChE Annual Meeting  \n",
      "128                          2022 AIChE Annual Meeting  \n",
      "129                          2022 AIChE Annual Meeting  \n",
      "130                          2022 AIChE Annual Meeting  \n",
      "132  2022 Spring Meeting & 18th Global Congress on ...  \n",
      "134                          2021 AIChE Annual Meeting  \n",
      "135                          2021 AIChE Annual Meeting  \n",
      "136                          2021 AIChE Annual Meeting  \n",
      "143                  2020 Virtual AIChE Annual Meeting  \n",
      "145                          2018 AIChE Annual Meeting  \n",
      "146                          2017 AIChE Annual Meeting  \n",
      "148                                                NaN  \n",
      "150                                                NaN  \n",
      "\n",
      "Unique 원본 Journal 값:\n",
      "['2023 IEEE 21st International Conference on Industrial Informatics (INDIN), 1-6'\n",
      " '2023 AIChE Annual Meeting' '2022 AIChE Annual Meeting'\n",
      " '2022 Spring Meeting & 18th Global Congress on Process Safety'\n",
      " '2021 AIChE Annual Meeting' '2020 Virtual AIChE Annual Meeting'\n",
      " '2018 AIChE Annual Meeting' '2017 AIChE Annual Meeting' nan\n",
      " '2025 AIChE Annual Meeting' '19th AIChE Annual Meeting'\n",
      " '8th International Symposium on Design, Operation and Control of Chemical …'\n",
      " '2018 KIChE Fall Meeting'\n",
      " '2015 15th International Conference on Control, Automation and Systems (ICCAS …']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ----------- 유틸 함수 -----------\n",
    "def normalize_journal(journal: str) -> str:\n",
    "    if pd.isna(journal) or str(journal).strip() == \"\":\n",
    "        return \"Unknown\"\n",
    "    j = re.sub(r\"\\d.*$\", \"\", str(journal)).strip()  # 숫자부터 뒤 제거\n",
    "    j = re.sub(r\"[-,:.;\\u00B7\\u2013\\u2014\\s]+$\", \"\", j).strip()  # 끝의 불필요 문자 제거\n",
    "    return j if j else \"Unknown\"\n",
    "\n",
    "# ----------- CSV 불러오기 -----------\n",
    "df = pd.read_csv(\"scholar_papers_all.csv\")  # 파일명 바꿔주세요\n",
    "\n",
    "# ----------- 정규화 컬럼 추가 -----------\n",
    "df[\"JournalClean\"] = df[\"Journal/Conference\"].apply(normalize_journal)\n",
    "\n",
    "# ----------- Unknown 항목만 필터링 -----------\n",
    "unknown_df = df[df[\"JournalClean\"] == \"Unknown\"]\n",
    "\n",
    "print(f\"총 Unknown 항목 수: {len(unknown_df)}\")\n",
    "print(unknown_df[[\"Professor\", \"Title\", \"Journal/Conference\"]].head(20))  # 상위 20개 미리보기\n",
    "\n",
    "# ----------- Unknown 원본 저널값 유니크 확인 -----------\n",
    "print(\"\\nUnique 원본 Journal 값:\")\n",
    "print(unknown_df[\"Journal/Conference\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93485eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 13:24:07,982 [INFO] ====== 조형태 교수님 (https://scholar.google.com/citations?hl=ko&user=QsjS7I4AAAAJ) 크롤링 시작 ======\n",
      "조형태 교수님 논문 처리 중:   2%|▏         | 3/154 [00:05<04:52,  1.94s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m     detail_url \u001b[38;5;241m=\u001b[39m base_url \u001b[38;5;241m+\u001b[39m detail_url\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# requests로 citation_for_view 페이지 요청\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetail_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser-Agent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMozilla/5.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(r\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m link_tag \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect_one(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#gsc_oci_title a.gsc_oci_title_link\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\requests\\models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:1088\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1088\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1090\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:1248\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1245\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1248\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1250\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:1167\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1167\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\PSID_PC_20\\anaconda3\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import logging\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "\n",
    "# ---------------- 로깅 설정 ----------------\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# ---------------- 대상 인물 리스트 ----------------\n",
    "professors = {\n",
    "    \"조형태 교수님\": \"https://scholar.google.com/citations?hl=ko&user=QsjS7I4AAAAJ\",\n",
    "    \"이재원 교수님\": \"https://scholar.google.co.kr/citations?user=guPkb4cAAAAJ&hl=ko\",\n",
    "    \"가성빈 교수님\": \"https://scholar.google.com/citations?hl=ko&user=YZ5rW_gAAAAJ\",\n",
    "    \"최동호\": \"https://scholar.google.com/citations?hl=ko&user=JHi2ay4AAAAJ\",\n",
    "    \"안나현\": \"https://scholar.google.com/citations?hl=ko&user=5gsoA1EAAAAJ\",\n",
    "    \"주종효\": \"https://scholar.google.co.kr/citations?user=GdFcc0QAAAAJ&hl=ko&oi=sra\",\n",
    "    \"김유림\": \"https://scholar.google.co.kr/citations?user=66OKDcgAAAAJ&hl=ko&oi=sra\",\n",
    "    \"윤승관\": \"https://scholar.google.co.kr/citations?user=HDVnd5YAAAAJ&hl=ko&oi=sra\",\n",
    "}\n",
    "\n",
    "# ---------------- 브라우저 실행 (논문 리스트만 Selenium으로) ----------------\n",
    "options = Options()\n",
    "# options.add_argument(\"--headless\")   # 무창 실행 원하면 주석 해제\n",
    "service = Service(\"chromedriver.exe\")   # 경로 수정 필요\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "results = []\n",
    "base_url = \"https://scholar.google.com\"\n",
    "\n",
    "# ---------------- 개별 교수님 순회 ----------------\n",
    "for prof_name, url in professors.items():\n",
    "    logging.info(f\"====== {prof_name} ({url}) 크롤링 시작 ======\")\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # \"더보기\" 버튼 계속 눌러서 모든 논문 로딩\n",
    "    while True:\n",
    "        try:\n",
    "            more_button = driver.find_element(By.ID, \"gsc_bpf_more\")\n",
    "            if more_button.is_enabled():\n",
    "                driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                time.sleep(1.2)\n",
    "            else:\n",
    "                break\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            break\n",
    "\n",
    "    # 논문 리스트 가져오기\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, \"tr.gsc_a_tr\")\n",
    "\n",
    "    for row in tqdm(rows, desc=f\"{prof_name} 논문 처리 중\"):\n",
    "        try:\n",
    "            title_elem = row.find_element(By.CSS_SELECTOR, \"a.gsc_a_at\")\n",
    "            title = title_elem.text\n",
    "            year = row.find_element(By.CSS_SELECTOR, \".gsc_a_y\").text\n",
    "\n",
    "            detail_url = title_elem.get_attribute(\"href\")\n",
    "            if detail_url.startswith(\"/\"):  # 상대 경로일 경우만 base_url 붙임\n",
    "                detail_url = base_url + detail_url\n",
    "\n",
    "            # requests로 citation_for_view 페이지 요청\n",
    "            r = requests.get(detail_url, headers={\"User-Agent\":\"Mozilla/5.0\"}, timeout=15)\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "            link_tag = soup.select_one(\"#gsc_oci_title a.gsc_oci_title_link\")\n",
    "            link = link_tag[\"href\"] if link_tag else \"\"\n",
    "\n",
    "            results.append([prof_name, title, year, link])\n",
    "\n",
    "            time.sleep(0.5)  # 요청 속도 제한 (차단 방지)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"{prof_name} 논문 처리 실패: {e}\")\n",
    "\n",
    "logging.info(\"===== 모든 교수님 크롤링 완료 =====\")\n",
    "\n",
    "# ---------------- CSV 저장 ----------------\n",
    "csv_filename = \"scholar_papers_links.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Professor\", \"Title\", \"Year\", \"Link\"])\n",
    "    writer.writerows(results)\n",
    "\n",
    "logging.info(f\"총 {len(results)}개 논문 링크를 {csv_filename}에 저장 완료\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ad92af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 13:24:47,772 [INFO] ====== 조형태 교수님 (https://scholar.google.com/citations?hl=ko&user=QsjS7I4AAAAJ) 크롤링 시작 ======\n",
      "조형태 교수님 논문 처리 중: 100%|██████████| 154/154 [00:13<00:00, 11.65it/s]\n",
      "2025-09-18 13:25:12,169 [INFO] ====== 이재원 교수님 (https://scholar.google.co.kr/citations?user=guPkb4cAAAAJ&hl=ko) 크롤링 시작 ======\n",
      "이재원 교수님 논문 처리 중: 100%|██████████| 56/56 [00:03<00:00, 14.31it/s] \n",
      "2025-09-18 13:25:24,787 [INFO] ====== 가성빈 교수님 (https://scholar.google.com/citations?hl=ko&user=YZ5rW_gAAAAJ) 크롤링 시작 ======\n",
      "가성빈 교수님 논문 처리 중: 100%|██████████| 48/48 [00:04<00:00, 11.01it/s]\n",
      "2025-09-18 13:25:34,951 [INFO] ====== 최동호 (https://scholar.google.com/citations?hl=ko&user=JHi2ay4AAAAJ) 크롤링 시작 ======\n",
      "최동호 논문 처리 중: 100%|██████████| 40/40 [00:01<00:00, 23.04it/s] \n",
      "2025-09-18 13:25:42,691 [INFO] ====== 안나현 (https://scholar.google.com/citations?hl=ko&user=5gsoA1EAAAAJ) 크롤링 시작 ======\n",
      "안나현 논문 처리 중: 100%|██████████| 18/18 [00:00<00:00, 19.63it/s]\n",
      "2025-09-18 13:25:48,186 [INFO] ====== 주종효 (https://scholar.google.co.kr/citations?user=GdFcc0QAAAAJ&hl=ko&oi=sra) 크롤링 시작 ======\n",
      "주종효 논문 처리 중: 100%|██████████| 49/49 [00:02<00:00, 18.71it/s]\n",
      "2025-09-18 13:25:57,136 [INFO] ====== 김유림 (https://scholar.google.co.kr/citations?user=66OKDcgAAAAJ&hl=ko&oi=sra) 크롤링 시작 ======\n",
      "김유림 논문 처리 중: 100%|██████████| 26/26 [00:01<00:00, 14.96it/s]\n",
      "2025-09-18 13:26:03,596 [INFO] ====== 윤승관 (https://scholar.google.co.kr/citations?user=HDVnd5YAAAAJ&hl=ko&oi=sra) 크롤링 시작 ======\n",
      "윤승관 논문 처리 중: 100%|██████████| 8/8 [00:00<00:00, 10.17it/s]\n",
      "2025-09-18 13:26:07,113 [INFO] ===== 모든 교수님 크롤링 완료 =====\n",
      "2025-09-18 13:26:07,117 [INFO] 총 399개 논문 링크를 scholar_papers_links.csv에 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import logging\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ---------------- 로깅 설정 ----------------\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "professors = {\n",
    "    \"조형태 교수님\": \"https://scholar.google.com/citations?hl=ko&user=QsjS7I4AAAAJ\",\n",
    "    \"이재원 교수님\": \"https://scholar.google.co.kr/citations?user=guPkb4cAAAAJ&hl=ko\",\n",
    "    \"가성빈 교수님\": \"https://scholar.google.com/citations?hl=ko&user=YZ5rW_gAAAAJ\",\n",
    "    \"최동호\": \"https://scholar.google.com/citations?hl=ko&user=JHi2ay4AAAAJ\",\n",
    "    \"안나현\": \"https://scholar.google.com/citations?hl=ko&user=5gsoA1EAAAAJ\",\n",
    "    \"주종효\": \"https://scholar.google.co.kr/citations?user=GdFcc0QAAAAJ&hl=ko&oi=sra\",\n",
    "    \"김유림\": \"https://scholar.google.co.kr/citations?user=66OKDcgAAAAJ&hl=ko&oi=sra\",\n",
    "    \"윤승관\": \"https://scholar.google.co.kr/citations?user=HDVnd5YAAAAJ&hl=ko&oi=sra\",\n",
    "}\n",
    "\n",
    "# ---------------- 브라우저 실행 (논문 리스트만 Selenium으로) ----------------\n",
    "options = Options()\n",
    "# options.add_argument(\"--headless\")   # 무창 실행 원하면 주석 해제\n",
    "service = Service(\"chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "results = []\n",
    "base_url = \"https://scholar.google.com\"\n",
    "\n",
    "# ---------------- 원문 링크 추출 함수 ----------------\n",
    "def fetch_detail(prof_name, title, year, detail_url):\n",
    "    try:\n",
    "        r = requests.get(detail_url, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=15)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        link_tag = soup.select_one(\"#gsc_oci_title a.gsc_oci_title_link\")\n",
    "        link = link_tag[\"href\"] if link_tag else \"\"\n",
    "        return [prof_name, title, year, link]\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"{prof_name} 논문 '{title}' 원문 링크 요청 실패: {e}\")\n",
    "        return [prof_name, title, year, \"\"]\n",
    "\n",
    "# ---------------- 개별 교수님 순회 ----------------\n",
    "for prof_name, url in professors.items():\n",
    "    logging.info(f\"====== {prof_name} ({url}) 크롤링 시작 ======\")\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # \"더보기\" 버튼 계속 눌러서 모든 논문 로딩\n",
    "    while True:\n",
    "        try:\n",
    "            more_button = driver.find_element(By.ID, \"gsc_bpf_more\")\n",
    "            if more_button.is_enabled():\n",
    "                driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                time.sleep(1.0)\n",
    "            else:\n",
    "                break\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            break\n",
    "\n",
    "    # 논문 리스트 가져오기\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, \"tr.gsc_a_tr\")\n",
    "    tasks = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:  # 동시 10개 요청\n",
    "        future_to_title = {}\n",
    "        for row in rows:\n",
    "            try:\n",
    "                title_elem = row.find_element(By.CSS_SELECTOR, \"a.gsc_a_at\")\n",
    "                title = title_elem.text\n",
    "                year = row.find_element(By.CSS_SELECTOR, \".gsc_a_y\").text\n",
    "                detail_url = title_elem.get_attribute(\"href\")\n",
    "                if detail_url.startswith(\"/\"):\n",
    "                    detail_url = base_url + detail_url\n",
    "\n",
    "                future = executor.submit(fetch_detail, prof_name, title, year, detail_url)\n",
    "                future_to_title[future] = title\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"{prof_name} 논문 row 처리 실패: {e}\")\n",
    "\n",
    "        for future in tqdm(as_completed(future_to_title), total=len(future_to_title), desc=f\"{prof_name} 논문 처리 중\"):\n",
    "            results.append(future.result())\n",
    "\n",
    "logging.info(\"===== 모든 교수님 크롤링 완료 =====\")\n",
    "\n",
    "# ---------------- CSV 저장 ----------------\n",
    "csv_filename = \"scholar_papers_links.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Professor\", \"Title\", \"Year\", \"Link\"])\n",
    "    writer.writerows(results)\n",
    "\n",
    "logging.info(f\"총 {len(results)}개 논문 링크를 {csv_filename}에 저장 완료\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48b83248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합된 데이터:   Professor                                              Title    Year  \\\n",
      "0   조형태 교수님  Techno‐economic comparison of amine regenerati...  2021.0   \n",
      "1   조형태 교수님  Multiobjective Optimization of Plastic Waste S...  2022.0   \n",
      "2   조형태 교수님  Multiobjective Optimization of Plastic Waste S...  2022.0   \n",
      "3   조형태 교수님  Optimization of wet flue gas desulfurization s...  2021.0   \n",
      "4   조형태 교수님  Novel waste heat and oil recovery system in th...  2022.0   \n",
      "\n",
      "                                                Link  \\\n",
      "0  https://scijournals.onlinelibrary.wiley.com/do...   \n",
      "1  https://pubs.acs.org/doi/abs/10.1021/acssusche...   \n",
      "2  https://pubs.acs.org/doi/abs/10.1021/acssusche...   \n",
      "3  https://www.sciencedirect.com/science/article/...   \n",
      "4  https://onlinelibrary.wiley.com/doi/abs/10.100...   \n",
      "\n",
      "                                  Journal/Conference  \n",
      "0     Energy Science & Engineering 9 (12), 2529-2543  \n",
      "1  ACS Sustainable Chemistry & Engineering 10 (40...  \n",
      "2  ACS Sustainable Chemistry & Engineering 10 (40...  \n",
      "3          Journal of Cleaner Production 318, 128492  \n",
      "4  International Journal of Energy Research 46 (1...  \n",
      "저널별 그룹핑 결과:                                Journal/Conference  Count\n",
      "7                       2022 AIChE Annual Meeting     26\n",
      "118  Energy Conversion and Management 268, 115981     16\n",
      "31                     Applied Energy 354, 122227     16\n",
      "9                       2023 AIChE Annual Meeting     12\n",
      "176     Journal of Cleaner Production 423, 138745      9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 불러오기\n",
    "df_all = pd.read_csv(\"scholar_papers_all.csv\")\n",
    "df_links = pd.read_csv(\"scholar_papers_links.csv\")\n",
    "\n",
    "# Title 기준 inner join (같은 논문만 매칭)\n",
    "df_merged = pd.merge(\n",
    "    df_links,\n",
    "    df_all[[\"Title\", \"Journal/Conference\"]],\n",
    "    on=\"Title\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 결과 저장\n",
    "df_merged.to_csv(\"scholar_papers_merged.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"병합된 데이터:\", df_merged.head())\n",
    "\n",
    "# ---------------- 저널별 그룹핑 ----------------\n",
    "journal_group = (\n",
    "    df_merged.groupby(\"Journal/Conference\")\n",
    "    .size()\n",
    "    .reset_index(name=\"Count\")\n",
    "    .sort_values(\"Count\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"저널별 그룹핑 결과:\", journal_group.head())\n",
    "\n",
    "# CSV로 저장\n",
    "journal_group.to_csv(\"journal_grouping.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05b08e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고유 저널 개수: 111\n",
      "['', '.', '19th AIChE Annual Meeting', '2015', '2017 AIChE Annual Meeting', '2018 AIChE Annual Meeting', '2018 KIChE Fall Meeting', '2020 Virtual AIChE Annual Meeting', '2021 AIChE Annual Meeting', '2022 AIChE Annual Meeting', '2022 Spring Meeting &', '2023 AIChE Annual Meeting', '2023 IEEE', '2025 AIChE Annual Meeting', '8th International Symposium on Design, Operation and Control of Chemical …', 'ACS Sustainable Chemistry & Engineering', 'ACS omega', 'AIChE Annual Meeting', 'Advanced Science', 'Algal Research']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df_all = pd.read_csv(\"scholar_papers_all.csv\")\n",
    "\n",
    "# Journal/Conference 컬럼에서 저널명만 추출\n",
    "def clean_journal(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # 숫자, 콤마 이후 제거 (볼륨/페이지 제거)\n",
    "    cleaned = re.sub(r\"\\s\\d.*$\", \"\", text.strip())\n",
    "    return cleaned\n",
    "\n",
    "df_all[\"Journal_clean\"] = df_all[\"Journal/Conference\"].apply(clean_journal)\n",
    "\n",
    "# 고유 저널 리스트\n",
    "unique_journals = sorted(df_all[\"Journal_clean\"].dropna().unique().tolist())\n",
    "\n",
    "print(\"고유 저널 개수:\", len(unique_journals))\n",
    "print(unique_journals[:20])  # 앞 20개만 보기\n",
    "\n",
    "# 필요시 CSV로 저장\n",
    "pd.Series(unique_journals).to_csv(\"unique_journals.csv\", index=False, header=[\"Journal\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51830864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링 후 저널 개수: 81\n",
      "['2023 IEEE', '8th International Symposium on Design, Operation and Control of Chemical …', 'ACS Sustainable Chemistry & Engineering', 'ACS omega', 'Advanced Science', 'Algal Research', 'Applied Catalysis B: Environmental', 'Applied Chemistry for Engineering', 'Applied Crystallography', 'Applied Energy', 'Applied Soft Computing', 'Applied Thermal Engineering', 'Aquaculture International', 'Available at SSRN', 'Bioresource Technology', 'Catalysis Today', 'Cell Reports Physical Science', 'ChemSusChem,', 'Chemical Engineering Journal', 'Chemical Engineering Transactions']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2023 IEEE',\n",
       " '8th International Symposium on Design, Operation and Control of Chemical …',\n",
       " 'ACS Sustainable Chemistry & Engineering',\n",
       " 'ACS omega',\n",
       " 'Advanced Science',\n",
       " 'Algal Research',\n",
       " 'Applied Catalysis B: Environmental',\n",
       " 'Applied Chemistry for Engineering',\n",
       " 'Applied Crystallography',\n",
       " 'Applied Energy',\n",
       " 'Applied Soft Computing',\n",
       " 'Applied Thermal Engineering',\n",
       " 'Aquaculture International',\n",
       " 'Available at SSRN',\n",
       " 'Bioresource Technology',\n",
       " 'Catalysis Today',\n",
       " 'Cell Reports Physical Science',\n",
       " 'ChemSusChem,',\n",
       " 'Chemical Engineering Journal',\n",
       " 'Chemical Engineering Transactions',\n",
       " 'Chemical Engineering Transactions,',\n",
       " 'Chemosphere',\n",
       " 'Clean Technology',\n",
       " 'Computer Aided Chemical Engineering',\n",
       " 'Computer Aided Chemical Engineering,',\n",
       " 'Computer Physics Communications',\n",
       " 'Computer aided chemical engineering',\n",
       " 'Computers & Chemical Engineering',\n",
       " 'Computers in Industry',\n",
       " 'DYCOPS-CAB',\n",
       " 'Data in brief',\n",
       " 'Desalination',\n",
       " 'ENGINEERING WITH COMPUTERS',\n",
       " 'Energies',\n",
       " 'Energy',\n",
       " 'Energy Conversion and Management',\n",
       " 'Energy Science & Engineering',\n",
       " 'Engineering Applications of Artificial Intelligence',\n",
       " 'Engineering with Computers',\n",
       " 'Environment international',\n",
       " 'Environmental Pollution',\n",
       " 'Expert Systems with Applications',\n",
       " 'Foundations of Molecular Modeling and Simulation',\n",
       " 'IFAC-PapersOnLine',\n",
       " 'Industrial & Engineering Chemistry Research',\n",
       " 'Industrial Crops and Products',\n",
       " 'International Communications in Heat and Mass Transfer',\n",
       " 'International Journal of Biological Macromolecules',\n",
       " 'International Journal of Energy Research',\n",
       " 'International Journal of Heat and Mass Transfer',\n",
       " 'International Journal of Intelligent Systems',\n",
       " 'Journal of Analytical and Applied Pyrolysis',\n",
       " 'Journal of CO2 Utilization',\n",
       " 'Journal of Chromatography A',\n",
       " 'Journal of Cleaner Production',\n",
       " 'Journal of Environmental Chemical Engineering',\n",
       " 'Journal of Environmental Informatics',\n",
       " 'Journal of Environmental Management',\n",
       " 'Journal of Hazardous Materials',\n",
       " 'Journal of Hydrogen and New Energy',\n",
       " 'Journal of Industrial and Engineering Chemistry',\n",
       " 'Journal of Materials Chemistry A',\n",
       " 'Journal of Water Process Engineering',\n",
       " 'Korea CCS',\n",
       " 'Korean Chemical Engineering Research',\n",
       " 'Korean Journal of Chemical Engineering',\n",
       " 'Mathematics',\n",
       " 'Molecular Systems Design & Engineering',\n",
       " 'PSE Asia',\n",
       " 'Particle Technology Forum',\n",
       " 'Polymers',\n",
       " 'Powder Technology',\n",
       " 'Proceedings of Kishem',\n",
       " 'Process Safety and Environmental Protection',\n",
       " 'Renewable and Sustainable Energy Reviews',\n",
       " 'Safety science',\n",
       " 'Science of The Total Environment',\n",
       " 'Science of the Total Environment',\n",
       " 'Sustainable Cities and Society',\n",
       " 'US Patent',\n",
       " 'Vsa Processes for Ammonia-Based Green Hydrogen Separation Via Multiscale Hts']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "filtered_journals = [\n",
    "    x for x in unique_journals\n",
    "    if len(x) > 5\n",
    "    and \"Meeting\" not in x\n",
    "    and \"Conference\" not in x\n",
    "    and not re.search(r\"[가-힣]\", x)   # 한글 포함된 경우 제외\n",
    "]\n",
    "\n",
    "print(\"필터링 후 저널 개수:\", len(filtered_journals))\n",
    "print(filtered_journals[:20])  # 앞 20개만 확인\n",
    "filtered_journals['2023 IEEE',\n",
    " '8th International Symposium on Design, Operation and Control of Chemical …',\n",
    " 'ACS Sustainable Chemistry & Engineering',\n",
    " 'ACS omega',\n",
    " 'Advanced Science',\n",
    " 'Algal Research',\n",
    " 'Applied Catalysis B: Environmental',\n",
    " 'Applied Chemistry for Engineering',\n",
    " 'Applied Crystallography',\n",
    " 'Applied Energy',\n",
    " 'Applied Soft Computing',\n",
    " 'Applied Thermal Engineering',\n",
    " 'Aquaculture International',\n",
    " 'Available at SSRN',\n",
    " 'Bioresource Technology',\n",
    " 'Catalysis Today',\n",
    " 'Cell Reports Physical Science',\n",
    " 'ChemSusChem,',\n",
    " 'Chemical Engineering Journal',\n",
    " 'Chemical Engineering Transactions',\n",
    " 'Chemical Engineering Transactions,',\n",
    " 'Chemosphere',\n",
    " 'Clean Technology',\n",
    " 'Computer Aided Chemical Engineering',\n",
    " 'Computer Aided Chemical Engineering,',\n",
    "...\n",
    " 'Science of The Total Environment',\n",
    " 'Science of the Total Environment',\n",
    " 'Sustainable Cities and Society',\n",
    " 'US Patent',\n",
    " 'Vsa Processes for Ammonia-Based Green Hydrogen Separation Via Multiscale Hts']\n",
    "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5d4b635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 13:41:22,080 [INFO] ==== Chemical Engineering Journal 논문 수집 중 ====\n",
      "2025-09-18 13:41:44,127 [INFO] ==== Energy Conversion and Management 논문 수집 중 ====\n",
      "2025-09-18 13:41:44,725 [INFO] ==== Journal of Cleaner Production 논문 수집 중 ====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Journal\n",
      "0      Chemical Engineering Journal\n",
      "1  Energy Conversion and Management\n",
      "2     Journal of Cleaner Production\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import logging\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "def fetch_papers_from_semanticscholar(journal, limit=100):\n",
    "    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "    params = {\n",
    "        \"query\": f'journal:\"{journal}\"',  # 저널 필드 지정\n",
    "        \"limit\": limit,\n",
    "        \"fields\": \"title,abstract\"\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, params=params, headers=HEADERS, timeout=30)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            texts = []\n",
    "            for item in data.get(\"data\", []):\n",
    "                title = item.get(\"title\", \"\")\n",
    "                abstract = item.get(\"abstract\", \"\")\n",
    "                if title or abstract:\n",
    "                    texts.append(f\"{title} {abstract}\")\n",
    "            return texts\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Semantic Scholar API 오류 ({journal}): {e}\")\n",
    "    return []\n",
    "\n",
    "\n",
    "def extract_keywords_tfidf(texts, topn=10):\n",
    "    \"\"\"TF-IDF로 키워드 상위 topn 추출\"\"\"\n",
    "    if not texts:\n",
    "        return []\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        max_features=5000,\n",
    "        ngram_range=(1,2)  # unigram + bigram\n",
    "    )\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    scores = X.toarray().sum(axis=0)\n",
    "    indices = scores.argsort()[::-1][:topn]\n",
    "    features = vectorizer.get_feature_names_out()\n",
    "    return [features[i] for i in indices]\n",
    "\n",
    "# ---------------- 실행 예시 ----------------\n",
    "journals = [\n",
    "    \"Chemical Engineering Journal\",\n",
    "    \"Energy Conversion and Management\",\n",
    "    \"Journal of Cleaner Production\"\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for j in journals:\n",
    "    logging.info(f\"==== {j} 논문 수집 중 ====\")\n",
    "    texts = fetch_papers_from_semanticscholar(j, limit=100)\n",
    "    keywords = extract_keywords_tfidf(texts, topn=10)\n",
    "    results[j] = keywords\n",
    "\n",
    "# DataFrame 변환\n",
    "df_keywords = pd.DataFrame.from_dict(results, orient=\"index\").reset_index()\n",
    "df_keywords.columns = [\"Journal\"] + [f\"Keyword_{i}\" for i in range(1, df_keywords.shape[1])]\n",
    "print(df_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a71f143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023 IEEE',\n",
       " '8th International Symposium on Design, Operation and Control of Chemical …',\n",
       " 'ACS Sustainable Chemistry & Engineering',\n",
       " 'ACS omega',\n",
       " 'Advanced Science',\n",
       " 'Algal Research',\n",
       " 'Applied Catalysis B: Environmental',\n",
       " 'Applied Chemistry for Engineering',\n",
       " 'Applied Crystallography',\n",
       " 'Applied Energy',\n",
       " 'Applied Soft Computing',\n",
       " 'Applied Thermal Engineering',\n",
       " 'Aquaculture International',\n",
       " 'Available at SSRN',\n",
       " 'Bioresource Technology',\n",
       " 'Catalysis Today',\n",
       " 'Cell Reports Physical Science',\n",
       " 'ChemSusChem,',\n",
       " 'Chemical Engineering Journal',\n",
       " 'Chemical Engineering Transactions',\n",
       " 'Chemical Engineering Transactions,',\n",
       " 'Chemosphere',\n",
       " 'Clean Technology',\n",
       " 'Computer Aided Chemical Engineering',\n",
       " 'Computer Aided Chemical Engineering,',\n",
       " 'Computer Physics Communications',\n",
       " 'Computer aided chemical engineering',\n",
       " 'Computers & Chemical Engineering',\n",
       " 'Computers in Industry',\n",
       " 'DYCOPS-CAB',\n",
       " 'Data in brief',\n",
       " 'Desalination',\n",
       " 'ENGINEERING WITH COMPUTERS',\n",
       " 'Energies',\n",
       " 'Energy',\n",
       " 'Energy Conversion and Management',\n",
       " 'Energy Science & Engineering',\n",
       " 'Engineering Applications of Artificial Intelligence',\n",
       " 'Engineering with Computers',\n",
       " 'Environment international',\n",
       " 'Environmental Pollution',\n",
       " 'Expert Systems with Applications',\n",
       " 'Foundations of Molecular Modeling and Simulation',\n",
       " 'IFAC-PapersOnLine',\n",
       " 'Industrial & Engineering Chemistry Research',\n",
       " 'Industrial Crops and Products',\n",
       " 'International Communications in Heat and Mass Transfer',\n",
       " 'International Journal of Biological Macromolecules',\n",
       " 'International Journal of Energy Research',\n",
       " 'International Journal of Heat and Mass Transfer',\n",
       " 'International Journal of Intelligent Systems',\n",
       " 'Journal of Analytical and Applied Pyrolysis',\n",
       " 'Journal of CO2 Utilization',\n",
       " 'Journal of Chromatography A',\n",
       " 'Journal of Cleaner Production',\n",
       " 'Journal of Environmental Chemical Engineering',\n",
       " 'Journal of Environmental Informatics',\n",
       " 'Journal of Environmental Management',\n",
       " 'Journal of Hazardous Materials',\n",
       " 'Journal of Hydrogen and New Energy',\n",
       " 'Journal of Industrial and Engineering Chemistry',\n",
       " 'Journal of Materials Chemistry A',\n",
       " 'Journal of Water Process Engineering',\n",
       " 'Korea CCS',\n",
       " 'Korean Chemical Engineering Research',\n",
       " 'Korean Journal of Chemical Engineering',\n",
       " 'Mathematics',\n",
       " 'Molecular Systems Design & Engineering',\n",
       " 'PSE Asia',\n",
       " 'Particle Technology Forum',\n",
       " 'Polymers',\n",
       " 'Powder Technology',\n",
       " 'Proceedings of Kishem',\n",
       " 'Process Safety and Environmental Protection',\n",
       " 'Renewable and Sustainable Energy Reviews',\n",
       " 'Safety science',\n",
       " 'Science of The Total Environment',\n",
       " 'Science of the Total Environment',\n",
       " 'Sustainable Cities and Society',\n",
       " 'US Patent',\n",
       " 'Vsa Processes for Ammonia-Based Green Hydrogen Separation Via Multiscale Hts']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_journals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
